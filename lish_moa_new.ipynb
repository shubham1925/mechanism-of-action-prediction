{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lish_moa_new.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeY8zdHrs7LP"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1MOLBLWX4-d"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow.keras.layers as L\n",
        "import tensorflow.keras.models as M\n",
        "import time\n",
        "import sys\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kESwrSmI2RJK"
      },
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/lish-moa/train_features.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/lish-moa/test_features.csv')\n",
        "targetns = pd.read_csv('/content/drive/MyDrive/lish-moa/train_targets_nonscored.csv')\n",
        "train_target_df = pd.read_csv('/content/drive/MyDrive/lish-moa/train_targets_scored.csv')\n",
        "sub = pd.read_csv('/content/drive/MyDrive/lish-moa/sample_submission.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVDxQfKS3AXe",
        "outputId": "95e395f6-5962-4564-d472-9336cd288577"
      },
      "source": [
        "target_cols = train_target_df.columns[1:]\n",
        "N_TARGETS = len(target_cols)\n",
        "print(train_df.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(23814, 876)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4Nvks1Z--8o"
      },
      "source": [
        "cells = [col for col in train_df.columns if col.startswith('c-')]\n",
        "genes = [col for col in train_df.columns if col.startswith('g-')]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2De-DZaFa5-3"
      },
      "source": [
        "# For g- features\n",
        "n_comp = 50\n",
        "data = pd.concat([pd.DataFrame(train_df[genes]), pd.DataFrame(test_df[genes])])\n",
        "data2 = (PCA(n_components = 50, random_state = 100).fit_transform(data[genes]))\n",
        "train2 = data2[:train_df.shape[0]]\n",
        "test2 = data2[-test_df.shape[0]:]\n",
        "\n",
        "train2 = pd.DataFrame(train2, columns = [f'pca_G-{i}' for i in range(50)])\n",
        "test2 = pd.DataFrame(test2, columns = [f'pca_G-{i}' for i in range(50)])\n",
        "\n",
        "train_df = pd.concat((train_df, train2), axis = 1)\n",
        "test_df = pd.concat((test_df, test2), axis = 1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPGwe49ac8CM"
      },
      "source": [
        "# For c- features\n",
        "data = pd.concat([pd.DataFrame(train_df[cells]), pd.DataFrame(test_df[cells])])\n",
        "data2 = (PCA(n_components = 15, random_state = 100).fit_transform(data[cells]))\n",
        "train2 = data2[:train_df.shape[0]]\n",
        "test2 = data2[-test_df.shape[0]:]\n",
        "\n",
        "train2 = pd.DataFrame(train2, columns = [f'pca_C-{i}' for i in range(15)])\n",
        "test2 = pd.DataFrame(test2, columns = [f'pca_C-{i}' for i in range(15)])\n",
        "train_df = pd.concat((train_df, train2), axis = 1)\n",
        "test_df = pd.concat((test_df, test2), axis = 1)\n",
        "train_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YlRDw0xdiof"
      },
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "train_copy = train_df\n",
        "var_thresh = VarianceThreshold(0.8)\n",
        "data = train_df.append(test_df)\n",
        "data_transformed = var_thresh.fit_transform(data.iloc[:, 4:])\n",
        "data_transformed.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mt1kT7TyeRnV"
      },
      "source": [
        "train_df_trans = data_transformed[ : train_df.shape[0]]\n",
        "test_df_trans = data_transformed[-test_df.shape[0] : ]\n",
        "\n",
        "train_df = pd.DataFrame(train_df[['sig_id', 'cp_type', 'cp_time', 'cp_dose']].values.reshape(-1, 4), columns = ['sig_id', 'cp_type', 'cp_time', 'cp_dose'])\n",
        "# train_df.head\n",
        "train_df = pd.concat([train_df, pd.DataFrame(train_df_trans)], axis = 1)\n",
        "\n",
        "\n",
        "test_df = pd.DataFrame(test_df[['sig_id', 'cp_type', 'cp_time', 'cp_dose']].values.reshape(-1, 4), columns = ['sig_id', 'cp_type', 'cp_time', 'cp_dose'])\n",
        "# train_df.head\n",
        "test_df = pd.concat([test_df, pd.DataFrame(test_df_trans)], axis = 1)\n",
        "train_df.head"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jufWOrsjd_x"
      },
      "source": [
        "search_row = dict(train_copy.iloc[0, 4:])\n",
        "col_rela = {}\n",
        "for i in np.arange(0, 868):\n",
        "  for k, v in search_row.items():\n",
        "    if train_df[i][0] == v.all():\n",
        "      col_rela[i] = k\n",
        "train_df = train_df.rename(columns = col_rela)\n",
        "test_df = test_df.rename(columns = col_rela)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8Mda3w8n7Sc"
      },
      "source": [
        "SEED = 1925\n",
        "EPOCHS = 25\n",
        "BATCH_SIZE = 128\n",
        "FOLDS = 5\n",
        "REPEATS = 5\n",
        "LR = 0.0005\n",
        "N_TARGETS = len(target_cols)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M1_8ksBo2LD"
      },
      "source": [
        "def seed_everything(seed):\n",
        "  np.random.seed(seed)\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "  tf.random.set_seed(seed)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ41d27KpHFN"
      },
      "source": [
        "def multi_log_loss(y_true, y_pred):\n",
        "  losses = []\n",
        "  for col in y_true.columns:\n",
        "    losses.append(log_loss(y_true.loc[:, col], y_pred.loc[:, col]))\n",
        "  return np.mean(losses)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdNyeb33pzF-"
      },
      "source": [
        "def preprocess_df(data):\n",
        "  # data['cp_type'] = (data['cp_type'] == 'trt_cp').astype(int)\n",
        "  # data['cp_dose'] = (data['cp_dose'] == 'D2').astype(int)\n",
        "  data.drop(['cp_type'], axis = 1, inplace = True)\n",
        "  data.loc[:, 'cp_dose'] = data.loc[:, 'cp_dose'].map({'D1':0, 'D2':1})\n",
        "  data.loc[:, 'cp_time'] = data.loc[:, 'cp_time'].map({24:0, 48:1, 72:2})\n",
        "  return data"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIz-efmeqG97"
      },
      "source": [
        "x_train = preprocess_df(train_df.drop(columns = \"sig_id\"))\n",
        "x_test = preprocess_df(test_df.drop(columns = \"sig_id\"))\n",
        "y_train = train_target_df.drop(columns = \"sig_id\")\n",
        "N_FEATURES = x_train.shape[1]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xytYuIpmqnTZ"
      },
      "source": [
        "x_train = x_train.astype({'cp_time':int})\n",
        "x_test = x_test.astype({'cp_time':int})\n",
        "x_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Pa34J9WZs9y"
      },
      "source": [
        "def create_model():\n",
        "  # model = tf.keras.Sequential([tf.keras.layers.Input(N_FEATURES), tf.keras.layers.BatchNormalization(),\n",
        "  #                              tf.keras.layers.Dropout(0.2), \n",
        "  #                              tfa.layers.WeightNormalization(tf.keras.layers.Dense(2048, activation = \"relu\")),\n",
        "  #                              tf.keras.layers.BatchNormalization(), tf.keras.layers.Dropout(0.5), \n",
        "  #                              tfa.layers.WeightNormalization(tf.keras.layers.Dense(2048, activation = \"relu\")),\n",
        "  #                              tf.keras.layers.BatchNormalization(), tf.keras.layers.Dropout(0.5),\n",
        "  #                              tfa.layers.WeightNormalization(tf.keras.layers.Dense(N_TARGETS, activation = \"sigmoid\"))])\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Input(N_FEATURES))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Dropout(0.2))\n",
        "  model.add(tfa.layers.WeightNormalization(tf.keras.layers.Dense(2048, activation = \"relu\")))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Dropout(0.5))\n",
        "  model.add(tfa.layers.WeightNormalization(tf.keras.layers.Dense(2048, activation = \"relu\")))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Dropout(0.5))\n",
        "  model.add(tfa.layers.WeightNormalization(tf.keras.layers.Dense(N_TARGETS, activation = \"sigmoid\")))\n",
        "  model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = LR), loss = 'binary_crossentropy', metrics = [\"accuracy\"])\n",
        "  return model"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsBfRn_xRDDC"
      },
      "source": [
        "def build_train(resume_models = None, repeat_number = 0, folds = 5, skip_folds = 0):\n",
        "  models = []\n",
        "  oof_preds = y_train.copy()\n",
        "  kfold = KFold(n_splits = folds, shuffle = True)\n",
        "  for fold, (train_ind, val_ind) in enumerate(kfold.split(x_train)):\n",
        "    print(f'Training fold {fold + 1}')\n",
        "    fold = fold + 1\n",
        "    cb_lr_schedule = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss', \n",
        "                                                          factor = 0.4, patience = 2, \n",
        "                                                          verbose = 1, min_delta = 0.0001, \n",
        "                                                          mode = 'auto')\n",
        "    checkpoint_path = f'repeat:{repeat_number}_Fold:{fold}.hdf5'\n",
        "    cb_checkpt = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor = 'val_loss', \n",
        "                                                    verbose = 0,\n",
        "                                                    save_best_only = True, save_weights_only = True, \n",
        "                                                    mode = 'min')\n",
        "    model = create_model()\n",
        "    model.fit(x_train.values[train_ind], y_train.values[train_ind], \n",
        "              validation_data = (x_train.values[val_ind], y_train.values[val_ind]),\n",
        "              callbacks = [cb_lr_schedule, cb_checkpt], epochs = EPOCHS, batch_size = BATCH_SIZE, verbose = 2)\n",
        "    model.load_weights(checkpoint_path)\n",
        "    oof_preds.loc[val_ind, :] = model.predict(x_train.values[val_ind])\n",
        "    models.append(model)\n",
        "    print('train:')\n",
        "    print(list(zip(model.metrics_names, model.evaluate(x_train.values[train_ind], y_train.values[train_ind], verbose = 0, batch_size = 32))))\n",
        "    print('val:')\n",
        "    print(list(zip(model.metrics_names, model.evaluate(x_train.values[train_ind], y_train.values[train_ind], verbose = 0, batch_size = 32))))\n",
        "    return models, oof_preds\n",
        "  "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh4Y1LfDVHnm"
      },
      "source": [
        "model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYphaA8kSYbY"
      },
      "source": [
        "models = []\n",
        "oof_preds = []\n",
        "# seed_everything(SEED)\n",
        "SEED_ARRAY = [0, 1, 2, 3, 4]\n",
        "for seed in SEED_ARRAY:\n",
        "  print(\"seed: \", seed)\n",
        "  seed_everything(seed)\n",
        "  for i in range(REPEATS):\n",
        "    m, oof = build_train(repeat_number = i, folds = FOLDS)\n",
        "    models = models + m\n",
        "    oof_preds.append(oof)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvPj3EsFiiNC"
      },
      "source": [
        "models[1].predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXHd2O4fzHYn"
      },
      "source": [
        "test_preds = sub.copy()\n",
        "test_preds[target_cols] = 0\n",
        "for model in models:\n",
        "  test_preds.loc[:, target_cols] += model.predict(x_test)\n",
        "test_preds.loc[:, target_cols] /= len(models)\n",
        "test_preds.loc[x_test['cp_type'] == 0, target_cols] = 0\n",
        "test_preds.to_csv('submission.csv', index = False)"
      ],
      "execution_count": 27,
      "outputs": []
    }
  ]
}